{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split \n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, SparkTrials, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "df = pd.read_csv(\"heart.csv\", sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split\n",
    "X = df.drop(\"target\",axis=1)\n",
    "y = df[\"target\"].values\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummies\n",
    "#TODO: Try this way\n",
    "X = pd.get_dummies(X, columns = ['cp','thal','slope'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = preprocessing.StandardScaler()\n",
    "minMax_scaler = preprocessing.MinMaxScaler()\n",
    "quantile_Tranformer_uniform = preprocessing.QuantileTransformer()\n",
    "normalizer = preprocessing.Normalizer()\n",
    "power_Transformer = preprocessing.PowerTransformer()\n",
    "\n",
    "X_standard = standard_scaler.fit_transform(X)\n",
    "X_minMax  = minMax_scaler.fit_transform(X)\n",
    "X_quantile = quantile_Tranformer_uniform.fit_transform(X)\n",
    "X_normalize = normalizer.fit_transform(X)\n",
    "X_power = power_Transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "scores = cross_val_score(svm, X_standard, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Accuracy: 0.83 (+/- 0.06)\n"
    }
   ],
   "source": [
    " print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'naive_bayes':\n",
    "        clf = BernoulliNB(**params)\n",
    "        data = X_power\n",
    "    elif classifier_type == 'ridge_Classifier':\n",
    "        clf = RidgeClassifier(**params)\n",
    "        data = X\n",
    "    elif classifier_type == 'logistic_regression':\n",
    "        clf = LogisticRegression(**params)\n",
    "        data = X_quantile\n",
    "    elif classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "        data = X_standard\n",
    "    elif classifier_type == 'knn':\n",
    "        clf = KNeighborsClassifier(**params)\n",
    "        data = X_minMax  \n",
    "    elif classifier_type == 'randomforest':\n",
    "        clf = RandomForestClassifier(**params)\n",
    "        data = X_normalize                \n",
    "    else:\n",
    "        return 0\n",
    "    accuracy = cross_val_score(clf, data, y).mean()\n",
    "    \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = hp.choice('classifier_type', [\n",
    "    {\n",
    "        'type': 'naive_bayes',\n",
    "    },\n",
    "    {\n",
    "        'type':'ridge_Classifier',\n",
    "        'alpha': hp.uniform('alpha', 0.0, 2.0)\n",
    "    },\n",
    "    {\n",
    "        'type': 'logistic_regression',\n",
    "        'penalty': hp.choice('penalty', ['l1', 'l2', 'elasticnet', 'none'])\n",
    "    },\n",
    "    {\n",
    "        'type': 'svm',\n",
    "        'C': hp.lognormal('C', 0, 1.0),\n",
    "        'kernel': hp.choice('kernel', ['linear', 'rbf','poly']),\n",
    "        'gamma': hp.uniform('gamma', 0, 20.0)\n",
    "\n",
    "    },\n",
    "    {\n",
    "        'type': 'knn',\n",
    "        'n_neighbors': hp.choice('knn_n_neighbors', range(1,50)),\n",
    "        'weights' :hp.choice('weights', ['uniform','distance']),\n",
    "        'metric': hp.choice('metric',['euclidean','manhattan', 'minkowski'])\n",
    "        \n",
    "\n",
    "    },\n",
    "    { 'type': 'randomforest',\n",
    "        'max_depth': hp.choice('max_depth', range(1,20)),\n",
    "        'max_features': hp.choice('max_features', range(1,5)),\n",
    "        'n_estimators': hp.choice('n_estimators', range(1,20)),\n",
    "        'criterion': hp.choice('criterion', [\"gini\", \"entropy\"])\n",
    "    }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "100%|██████████| 100/100 [00:04<00:00, 20.33trial/s, best loss: -0.838360655737705]\n"
    }
   ],
   "source": [
    "trials = Trials()\n",
    "algo=tpe.suggest\n",
    "best_result = fmin(\n",
    "    fn=objective, \n",
    "    space=search_space,\n",
    "    algo=algo,\n",
    "    max_evals=100,\n",
    "    trials=trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'classifier_type': 0}\n"
    }
   ],
   "source": [
    "print(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objectiveWithoutScaling(params):\n",
    "    classifier_type = params['type']\n",
    "    del params['type']\n",
    "    if classifier_type == 'naive_bayes':\n",
    "        clf = BernoulliNB(**params)\n",
    "    elif classifier_type == 'ridge_Classifier':\n",
    "        clf = RidgeClassifier(**params)\n",
    "    elif classifier_type == 'logistic_regression':\n",
    "        clf = LogisticRegression(**params)\n",
    "    elif classifier_type == 'svm':\n",
    "        clf = SVC(**params)\n",
    "    elif classifier_type == 'knn':\n",
    "        clf = KNeighborsClassifier(**params)  \n",
    "    elif classifier_type == 'randomforest':\n",
    "        clf = RandomForestClassifier(**params)                \n",
    "    else:\n",
    "        return 0\n",
    "    accuracy = cross_val_score(clf, X_standard, y).mean()\n",
    "    \n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "100%|██████████| 100/100 [00:04<00:00, 23.39trial/s, best loss: -0.8415846994535519]\n"
    }
   ],
   "source": [
    "trials2 = Trials()\n",
    "algo=tpe.suggest\n",
    "best_result = fmin(\n",
    "    fn=objectiveWithoutScaling, \n",
    "    space=search_space,\n",
    "    algo=algo,\n",
    "    max_evals=100,\n",
    "    trials=trials2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'classifier_type': 0}\n"
    }
   ],
   "source": [
    "print(best_result)"
   ]
  }
 ]
}